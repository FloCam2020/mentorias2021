{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "atFi1riTXW8Y"
   },
   "outputs": [],
   "source": [
    "pip install pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MVoS9537wCjV"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import KBinsDiscretizer, OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, ComplementNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hnde3S2mXbaZ"
   },
   "outputs": [],
   "source": [
    "import pycaret.classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "EmrIjBi2Xdu8"
   },
   "outputs": [],
   "source": [
    "# Opción para ver todas las columnas del dataset en el notebook\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imwPHmuBXeYn"
   },
   "source": [
    "# Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7dL-GU6EXoNL"
   },
   "outputs": [],
   "source": [
    "# Leemos el dataset con la función de pandas \"read_csv\"\n",
    "key = \"data/bank-additional-full.csv\"\n",
    "df = pd.read_csv(key, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos los outliers de Campaign:\n",
    "\n",
    "q975_campaign=df.campaign.quantile(0.975)\n",
    "df.drop(df[df.campaign >= q975_campaign].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "yBfa-VDsXq30",
    "outputId": "53e1cd5a-f42a-4f33-b2cb-abc13650d0e4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "\n",
       "  month day_of_week  duration  campaign  pdays  previous     poutcome  \\\n",
       "0   may         mon       261         1    999         0  nonexistent   \n",
       "1   may         mon       149         1    999         0  nonexistent   \n",
       "\n",
       "   emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0           1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "1           1.1          93.994          -36.4      4.857       5191.0  no  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EH4RXMMCX2HD"
   },
   "source": [
    "# División en grupo de test y train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "1ajvhNHdYEzA"
   },
   "outputs": [],
   "source": [
    "# Reemplazamos la columna y (target) por 1 y 0\n",
    "df.y = df.y.replace('yes', 1)\n",
    "df.y = df.y.replace('no', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "yJE7k8L-X6Zw"
   },
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, stratify=df.y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "afLGjz1IYR6A"
   },
   "source": [
    "### Análisis global con PyCaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "cbe5a5d40f164b078a980567b7a8e70e",
      "47482f9ee49d4fcba87f4c0b2397a119",
      "a0adfdf2dafb429797aed840ce0131c1",
      "4e5bf7196dd84ad6ac9b3983e1077c0c",
      "bd7ee1d668b149f8850b1476ab82a529",
      "c19cf648a61745f58eb9b81291f7b17f"
     ]
    },
    "id": "L3Tuy7rzYMwI",
    "outputId": "c369b5e0-4306-4d5f-8697-643e0ba151ea"
   },
   "outputs": [],
   "source": [
    "from pycaret.classification import *\n",
    "clf = setup(data = df_train, target =\"y\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457,
     "referenced_widgets": [
      "3555dfc1ef634a54b67274a1dbbd92f6",
      "2508604ac6534766b142d8a9d86c12d2",
      "f3ad3c2cac724e099170823b2dc49978"
     ]
    },
    "id": "8bJ3Z1dtYbtC",
    "outputId": "c3b434ac-4061-46f0-86bf-19d5eaedb656"
   },
   "outputs": [],
   "source": [
    "#best = compare_models()\n",
    "best = compare_models(sort = 'f1') #default is 'Accuracy', LO CAMBIO POR F1 QUE ES LA QUE TOMAMOS COMO REFERENCIA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D4AEHKUwYjPO"
   },
   "source": [
    "### Continúo división train, test y validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ztImkemHYoJQ"
   },
   "outputs": [],
   "source": [
    "X = df.drop(columns='y')\n",
    "y = df.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "3CiSSI7jYsoe"
   },
   "outputs": [],
   "source": [
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3bVT55M0YvYO",
    "outputId": "428b3f0a-a7b8-498c-b89f-59620f0c483a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32075, 20), (32075,), (8019, 20), (8019,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_temp.shape, y_temp.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8pPgD6QqYxcT"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.2, stratify=y_temp, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "riAy7IF0Y17I",
    "outputId": "5e2e18ee-15d6-4707-d7c5-8c67fdea988a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25660, 20), (25660,), (6415, 20), (6415,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXm04ExSZpZu"
   },
   "source": [
    "# Pre-procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ry96jrO7Zrna"
   },
   "outputs": [],
   "source": [
    "#Todas las variables del dataset\n",
    "variables_categoricas_original = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome']\n",
    "variables_numericas_original = ['age', 'duration', 'campaign', 'pdays', 'previous','emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u0bkciXrZ0EO"
   },
   "outputs": [],
   "source": [
    "#Las variables que identificamos como relevantes\n",
    "variables_categoricas = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'poutcome']\n",
    "variables_numericas = ['age', 'campaign', 'previous', 'cons.conf.idx', 'euribor3m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "uq2mGq_yZ8wm"
   },
   "outputs": [],
   "source": [
    "class SelectColumnsTransformer():\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        cpy_df = X[self.columns].copy()\n",
    "        return cpy_df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o_SqY0e-aCgt"
   },
   "outputs": [],
   "source": [
    "#Aplicamos las transformaciones previas a los conjuntos de Train y Validation\n",
    "variables_categoricas = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'poutcome']\n",
    "variables_numericas = ['age', 'campaign', 'previous', 'cons.conf.idx', 'euribor3m']\n",
    "\n",
    "# Filtramos las variables que seleccionamos\n",
    "X_t = X_train[variables_categoricas + variables_numericas]\n",
    "X_v = X_val[variables_categoricas + variables_numericas]     \n",
    "\n",
    "pipeline_numerico = Pipeline([('select_numeric_columns', SelectColumnsTransformer(variables_numericas)),\n",
    "                             #('standard_scaler', StandardScaler()),\n",
    "                              (\"kbins_discretizer\", KBinsDiscretizer(n_bins=5, encode=\"ordinal\", strategy=\"quantile\"))      #strategy=\"uniform\"\n",
    "                            ])\n",
    "\n",
    "pipeline_categorico = Pipeline ([('select_categoric_columns', SelectColumnsTransformer(variables_categoricas)),\n",
    "                                  ('imputer', SimpleImputer(strategy='most_frequent', missing_values=\"unknown\")),      #podríamos no ponerlo, y que deje \"desconocido\" como una categoría más\n",
    "                                 ('cat', OneHotEncoder())])\n",
    "\n",
    "pipeline_completo = ColumnTransformer([('num', pipeline_numerico, variables_numericas),\n",
    "                                       ('cat', pipeline_categorico, variables_categoricas)\n",
    "                                      ])\n",
    "\n",
    "\n",
    "train = pipeline_completo.fit_transform(X_t)\n",
    "val = pipeline_completo.fit_transform(X_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_v82tE-qaYig"
   },
   "source": [
    "# Métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQv_X1BWaaSw"
   },
   "source": [
    "Dado el desbalance de casos con que cuenta este dataset, las métricas a tomar en consideración para el análisis son: AUC y F1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k034U3wuaws4"
   },
   "source": [
    "# Testeo por modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RPC5x8pia8CE"
   },
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W4NmvIKqb3G_"
   },
   "outputs": [],
   "source": [
    "variables_categoricas = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'poutcome']\n",
    "variables_numericas = ['age', 'campaign', 'previous', 'cons.conf.idx', 'euribor3m']\n",
    "\n",
    "# Filtramos las variables que seleccionamos\n",
    "X_t = X_train[variables_categoricas + variables_numericas]\n",
    "\n",
    "pipeline_numerico = Pipeline([('select_numeric_columns', SelectColumnsTransformer(variables_numericas)),\n",
    "                             #('standard_scaler', StandardScaler()),\n",
    "                             # (\"kbins_discretizer\", KBinsDiscretizer(n_bins=5, encode=\"ordinal\", strategy=\"quantile\"))      #strategy=\"uniform\"\n",
    "                            ])\n",
    "\n",
    "pipeline_categorico = Pipeline ([('select_categoric_columns', SelectColumnsTransformer(variables_categoricas)),\n",
    "                                 #('imputer', SimpleImputer(strategy='most_frequent', missing_values=\"unknown\")),      #podríamos no ponerlo, y que deje \"desconocido\" como una categoría más\n",
    "                                 ('cat', OneHotEncoder())])\n",
    "\n",
    "pipeline_completo = ColumnTransformer([('num', pipeline_numerico, variables_numericas),\n",
    "                                   ('cat', pipeline_categorico, variables_categoricas),\n",
    "                                  ])\n",
    "\n",
    "pipeline_modelo = Pipeline([('preprocess', pipeline_completo),\n",
    "                            ('dt', DecisionTreeClassifier(random_state=0, class_weight=\"balanced\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "13kNKjXdcxNB",
    "outputId": "7aaed30c-803a-4d19-dfb7-46c9b50485ad"
   },
   "outputs": [],
   "source": [
    "pipeline_modelo.fit(X_t, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w1w7x5Jgc8bC",
    "outputId": "30b50ff2-476b-4886-8a43-0f02cf094aae"
   },
   "outputs": [],
   "source": [
    "cross_validate(pipeline_modelo, X_t, y_train, cv=5, scoring=('precision','recall','f1', 'roc_auc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "630-DHgW2z3x"
   },
   "source": [
    "Análisis de estos resultados sobre el conjunto de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KKbU5FyoJOkJ"
   },
   "outputs": [],
   "source": [
    "train=pipeline_completo.fit_transform(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ByUgiL57Indg",
    "outputId": "d92b0b2a-bafd-4e81-b505-f4199de9f5d0"
   },
   "outputs": [],
   "source": [
    "dt=DecisionTreeClassifier(random_state=0, class_weight=\"balanced\")\n",
    "dt.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qy7425qe2zXM"
   },
   "outputs": [],
   "source": [
    "X_v=X_val[variables_categoricas + variables_numericas]\n",
    "val=pipeline_completo.fit_transform(X_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oAFs5_BR3atU",
    "outputId": "fce73cf3-f1e9-41aa-d6ca-33ffd6a6f8ce"
   },
   "outputs": [],
   "source": [
    "y_val_pred=dt.predict(val)\n",
    "print(\"VALIDACIÓN\")\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CmsdLTDQazQM"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EK4giNb9d-tK"
   },
   "outputs": [],
   "source": [
    "variables_categoricas = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'poutcome']\n",
    "variables_numericas = ['age', 'campaign', 'previous', 'cons.conf.idx', 'euribor3m']\n",
    "\n",
    "# Filtramos las variables que seleccionamos\n",
    "X_t = X_train[variables_categoricas + variables_numericas]\n",
    "\n",
    "pipeline_numerico = Pipeline([('select_numeric_columns', SelectColumnsTransformer(variables_numericas)),\n",
    "                             ('standard_scaler', StandardScaler()),\n",
    "                             # (\"kbins_discretizer\", KBinsDiscretizer(n_bins=5, encode=\"ordinal\", strategy=\"quantile\"))      #strategy=\"uniform\"\n",
    "                            ])\n",
    "\n",
    "pipeline_categorico = Pipeline ([('select_categoric_columns', SelectColumnsTransformer(variables_categoricas)),\n",
    "                                 # ('imputer', SimpleImputer(strategy='most_frequent', missing_values=\"unknown\")),      #podríamos no ponerlo, y que deje \"desconocido\" como una categoría más\n",
    "                                 ('cat', OneHotEncoder())])\n",
    "\n",
    "pipeline_completo = ColumnTransformer([('num', pipeline_numerico, variables_numericas),\n",
    "                                   ('cat', pipeline_categorico, variables_categoricas),\n",
    "                                  ])\n",
    "\n",
    "pipeline_modelo = Pipeline([('preprocess', pipeline_completo),\n",
    "                            ('lr', LogisticRegression(random_state=0, class_weight=\"balanced\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ap9C6kpPeekL",
    "outputId": "9da2d77f-c74a-49e4-a448-c8fc7bd696bc"
   },
   "outputs": [],
   "source": [
    "pipeline_modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1sNcoru0ekFQ",
    "outputId": "30bad373-47e4-49a0-fa02-d88b6e8d493e"
   },
   "outputs": [],
   "source": [
    "cross_validate(pipeline_modelo, X_t, y_train, cv=5, scoring=('f1', 'roc_auc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NVDER0X6a3V_"
   },
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xPBy-OLXevJU"
   },
   "outputs": [],
   "source": [
    "variables_categoricas = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'poutcome']\n",
    "variables_numericas = ['age', 'campaign', 'previous', 'cons.conf.idx', 'euribor3m']\n",
    "\n",
    "# Filtramos las variables que seleccionamos\n",
    "X_t = X_train[variables_categoricas + variables_numericas]\n",
    "\n",
    "pipeline_numerico = Pipeline([('select_numeric_columns', SelectColumnsTransformer(variables_numericas)),\n",
    "                             # ('standard_scaler', StandardScaler()),\n",
    "                             # (\"kbins_discretizer\", KBinsDiscretizer(n_bins=5, encode=\"ordinal\", strategy=\"quantile\"))      #strategy=\"uniform\"\n",
    "                            ])\n",
    "\n",
    "pipeline_categorico = Pipeline ([('select_categoric_columns', SelectColumnsTransformer(variables_categoricas)),\n",
    "                                 # ('imputer', SimpleImputer(strategy='most_frequent', missing_values=\"unknown\")),      #podríamos no ponerlo, y que deje \"desconocido\" como una categoría más\n",
    "                                 ('cat', OneHotEncoder())])\n",
    "\n",
    "pipeline_completo = ColumnTransformer([('num', pipeline_numerico, variables_numericas),\n",
    "                                   ('cat', pipeline_categorico, variables_categoricas),\n",
    "                                  ])\n",
    "\n",
    "pipeline_modelo = Pipeline([('preprocess', pipeline_completo),\n",
    "                            ('svm', SVC(random_state=0, class_weight=\"balanced\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mOVOXj_-fTkj",
    "outputId": "b8399b75-d606-4aeb-aace-a5b0b747d69c"
   },
   "outputs": [],
   "source": [
    "pipeline_modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aMiG5jDlfTZk",
    "outputId": "13960854-7d73-4deb-a433-7c7afea855e4"
   },
   "outputs": [],
   "source": [
    "cross_validate(pipeline_modelo, X_t, y_train, cv=5, scoring=('f1', 'roc_auc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LY3O4Z_Ya6Hz"
   },
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x2L8Cj4zfu9x"
   },
   "outputs": [],
   "source": [
    "variables_categoricas = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'poutcome']\n",
    "variables_numericas = ['age', 'campaign', 'previous', 'cons.conf.idx', 'euribor3m']\n",
    "\n",
    "# Filtramos las variables que seleccionamos\n",
    "X_t = X_train[variables_categoricas + variables_numericas]\n",
    "X_v = X_val[variables_categoricas + variables_numericas]\n",
    "\n",
    "pipeline_numerico = Pipeline([('select_numeric_columns', SelectColumnsTransformer(variables_numericas)),\n",
    "                             # ('standard_scaler', StandardScaler()),\n",
    "                             (\"kbins_discretizer\", KBinsDiscretizer(n_bins=4, encode=\"ordinal\", strategy=\"uniform\")),   #strategy=\"uniform\"\n",
    "                             ('bins_cat', OneHotEncoder())\n",
    "                            ])\n",
    "\n",
    "pipeline_categorico = Pipeline ([('select_categoric_columns', SelectColumnsTransformer(variables_categoricas)),\n",
    "                                 #('imputer', SimpleImputer(strategy='most_frequent', missing_values=\"unknown\")),      #podríamos no ponerlo, y que deje \"desconocido\" como una categoría más\n",
    "                                 ('cat', OneHotEncoder())\n",
    "                                 ])\n",
    "\n",
    "pipeline_completo = ColumnTransformer([('num', pipeline_numerico, variables_numericas),\n",
    "                                   ('cat', pipeline_categorico, variables_categoricas),\n",
    "                                  ])\n",
    "\n",
    "pipeline_modelo = Pipeline([('preprocess', pipeline_completo),\n",
    "                            ('nb', ComplementNB())])\n",
    "\n",
    "#The Complement Naive Bayes classifier was designed to correct the “severe assumptions” made by the standard Multinomial Naive Bayes classifier. It is particularly suited for imbalanced data sets.\n",
    "#En el pre-procesamiento transformé todos los atributos en categóricos, porque es el requerimiento del tipo de modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vUwDaC1gfw-Z"
   },
   "outputs": [],
   "source": [
    "pipeline_modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b44su-Wgfw2r",
    "outputId": "b0b3ff12-175a-4ed2-8571-06bea6b34393"
   },
   "outputs": [],
   "source": [
    "#Cross validation con toda la estimación sobre X_train\n",
    "cross_validate(pipeline_modelo, X_t, y_train, cv=5, scoring=('f1', 'roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tusr6z4cXbmw"
   },
   "outputs": [],
   "source": [
    "#Pre-procesamiento\n",
    "train = pipeline_completo.fit_transform(X_t)\n",
    "val = pipeline_completo.transform(X_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k8wyERDtXpGj",
    "outputId": "13bf9177-6257-4497-819c-0d603c503744"
   },
   "outputs": [],
   "source": [
    "nb=ComplementNB()\n",
    "nb.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QeSv1ZzPYOPW",
    "outputId": "e40bba10-fdb4-4497-b62d-362bb90b24ae"
   },
   "outputs": [],
   "source": [
    "print(\"MÉTRICAS CONJUNTO DE TRAIN\")\n",
    "print(classification_report(y_train, nb.predict(train)))\n",
    "print(\"MÉTRICAS CONJUNTO DE VALIDACIÓN\")\n",
    "print(classification_report(y_val, nb.predict(val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KTRoicEBystp"
   },
   "outputs": [],
   "source": [
    "#Optimización de hiperparámetros\n",
    "#Grilla de parámetros\n",
    "params={'alpha':[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.1, 1.3, 1.5],\n",
    "        'fit_prior':[True, False],\n",
    "        'norm':[True,False]\n",
    "       }\n",
    "\n",
    "nb=ComplementNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UHgG1hLfe5sb",
    "outputId": "45dc77a7-42d4-4760-c8e0-3911d9ab557b"
   },
   "outputs": [],
   "source": [
    "#Búsqueda de parámetros\n",
    "cv_nb = GridSearchCV(nb, params, scoring='f1', cv=5,refit=True,n_jobs=-1)     \n",
    "cv_nb.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-x9UAenTfIK_",
    "outputId": "6a658b44-f653-4903-ae56-0afceb334bac"
   },
   "outputs": [],
   "source": [
    "cv_nb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6fhDUfgkfLmw",
    "outputId": "1d50ea84-8338-441f-bb3f-373592735346"
   },
   "outputs": [],
   "source": [
    "#Entrenamiento de la mejor versión encontrada del modelo\n",
    "nb_best = ComplementNB(alpha=0.8, fit_prior=True, norm=True)\n",
    "nb_best.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GKAizGsEfWPY",
    "outputId": "8a8a9d9b-68dc-4e0f-b540-de151225c6f9"
   },
   "outputs": [],
   "source": [
    "print(\"MÉTRICAS CONJUNTO DE TRAIN\")\n",
    "print(classification_report(y_train, nb_best.predict(train)))\n",
    "print(\"MÉTRICAS CONJUNTO DE VALIDACIÓN\")\n",
    "print(classification_report(y_val, nb_best.predict(val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7IY52q1QbPfl"
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H1w20e0Dgafp"
   },
   "outputs": [],
   "source": [
    "variables_categoricas = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'poutcome']\n",
    "variables_numericas = ['age', 'campaign', 'previous', 'cons.conf.idx', 'euribor3m']\n",
    "\n",
    "# Filtramos las variables que seleccionamos\n",
    "X_t = X_train[variables_categoricas + variables_numericas]\n",
    "\n",
    "pipeline_numerico = Pipeline([('select_numeric_columns', SelectColumnsTransformer(variables_numericas)),\n",
    "                             # ('standard_scaler', StandardScaler()),\n",
    "                             # (\"kbins_discretizer\", KBinsDiscretizer(n_bins=5, encode=\"ordinal\", strategy=\"quantile\"))      #strategy=\"uniform\"\n",
    "                            ])\n",
    "\n",
    "pipeline_categorico = Pipeline ([('select_categoric_columns', SelectColumnsTransformer(variables_categoricas)),\n",
    "                                 # ('imputer', SimpleImputer(strategy='most_frequent', missing_values=\"unknown\")),      #podríamos no ponerlo, y que deje \"desconocido\" como una categoría más\n",
    "                                 ('cat', OneHotEncoder())])\n",
    "\n",
    "pipeline_completo = ColumnTransformer([('num', pipeline_numerico, variables_numericas),\n",
    "                                   ('cat', pipeline_categorico, variables_categoricas),\n",
    "                                  ])\n",
    "\n",
    "pipeline_modelo = Pipeline([('preprocess', pipeline_completo),\n",
    "                            ('rf', RandomForestClassifier(random_state=0, class_weight=\"balanced\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GT2AykV_gg92",
    "outputId": "3fc817fe-1bdb-4413-b199-614b1c2e7be6"
   },
   "outputs": [],
   "source": [
    "pipeline_modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jQJWTuB7gg1W",
    "outputId": "f4696bd5-a45a-4df6-ce53-984928decef5"
   },
   "outputs": [],
   "source": [
    "cross_validate(pipeline_modelo, X_t, y_train, cv=5, scoring=('f1', 'roc_auc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_NzdftPbSMS"
   },
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jFbPR-MshMZG"
   },
   "outputs": [],
   "source": [
    "variables_categoricas = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'poutcome']\n",
    "variables_numericas = ['age', 'campaign', 'previous', 'cons.conf.idx', 'euribor3m']\n",
    "\n",
    "# Filtramos las variables que seleccionamos\n",
    "X_t = X_train[variables_categoricas + variables_numericas]\n",
    "\n",
    "pipeline_numerico = Pipeline([('select_numeric_columns', SelectColumnsTransformer(variables_numericas)),\n",
    "                             ('standard_scaler', StandardScaler()),\n",
    "                             # (\"kbins_discretizer\", KBinsDiscretizer(n_bins=5, encode=\"ordinal\", strategy=\"quantile\"))      #strategy=\"uniform\"\n",
    "                            ])\n",
    "\n",
    "pipeline_categorico = Pipeline ([('select_categoric_columns', SelectColumnsTransformer(variables_categoricas)),\n",
    "                                 # ('imputer', SimpleImputer(strategy='most_frequent', missing_values=\"unknown\")),      #podríamos no ponerlo, y que deje \"desconocido\" como una categoría más\n",
    "                                 ('cat', OneHotEncoder())])\n",
    "\n",
    "pipeline_completo = ColumnTransformer([('num', pipeline_numerico, variables_numericas),\n",
    "                                   ('cat', pipeline_categorico, variables_categoricas),\n",
    "                                  ])\n",
    "\n",
    "pipeline_modelo = Pipeline([('preprocess', pipeline_completo),\n",
    "                            ('knn', KNeighborsClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3w8teqfWhgwx",
    "outputId": "1a5a1eef-4cca-46fe-d672-816cc0e1d45d"
   },
   "outputs": [],
   "source": [
    "pipeline_modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sowq0JZ9hM8U",
    "outputId": "e3af3a06-9143-4b65-a9ea-8ffd58fb74a9"
   },
   "outputs": [],
   "source": [
    "cross_validate(pipeline_modelo, X_t, y_train, cv=5, scoring=('f1', 'roc_auc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXPKooGubWmt"
   },
   "source": [
    "## Modelos Tree Based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhdfrtgbbZgl"
   },
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iBCV5nvGxooE"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "U0ZF4Bk9h33n"
   },
   "outputs": [],
   "source": [
    "variables_categoricas = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'poutcome']\n",
    "variables_numericas = ['age', 'campaign', 'previous', 'cons.conf.idx', 'euribor3m']\n",
    "\n",
    "# Filtramos las variables que seleccionamos\n",
    "X_t = X_train[variables_categoricas + variables_numericas]\n",
    "\n",
    "pipeline_numerico = Pipeline([('select_numeric_columns', SelectColumnsTransformer(variables_numericas)),\n",
    "                             # ('standard_scaler', StandardScaler()),\n",
    "                             # (\"kbins_discretizer\", KBinsDiscretizer(n_bins=5, encode=\"ordinal\", strategy=\"quantile\"))      #strategy=\"uniform\"\n",
    "                            ])\n",
    "\n",
    "pipeline_categorico = Pipeline ([('select_categoric_columns', SelectColumnsTransformer(variables_categoricas)),\n",
    "                                 #('imputer', SimpleImputer(strategy='most_frequent', missing_values=\"unknown\")),      #podríamos no ponerlo, y que deje \"desconocido\" como una categoría más\n",
    "                                 ('cat', OneHotEncoder())])\n",
    "\n",
    "pipeline_completo = ColumnTransformer([('num', pipeline_numerico, variables_numericas),\n",
    "                                   ('cat', pipeline_categorico, variables_categoricas),\n",
    "                                  ])\n",
    "\n",
    "pipeline_modelo = Pipeline([('preprocess', pipeline_completo),\n",
    "                            ('xgb', xgb.XGBClassifier(seed=0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PRx5rJ8FiCTF",
    "outputId": "c4fd9491-4e09-4511-d2c7-3d0fad69f09e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:11:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocess',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('select_numeric_columns',\n",
       "                                                                   <__main__.SelectColumnsTransformer object at 0x00000094C3E95340>)]),\n",
       "                                                  ['age', 'campaign',\n",
       "                                                   'previous', 'cons.conf.idx',\n",
       "                                                   'euribor3m']),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('select_categoric_columns',\n",
       "                                                                   <__main__.SelectColumnsTransformer object at 0x00000094E9C35220>),\n",
       "                                                                  (...\n",
       "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "                               importance_type='gain',\n",
       "                               interaction_constraints='',\n",
       "                               learning_rate=0.300000012, max_delta_step=0,\n",
       "                               max_depth=6, min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=100,\n",
       "                               n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               seed=0, subsample=1, tree_method='exact',\n",
       "                               validate_parameters=1, verbosity=None))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_modelo.fit(X_t, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HM-DFml8ld_T",
    "outputId": "7a24523b-a749-4853-a06f-1af16f03bd58"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:12:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:12:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:12:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:12:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:12:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([2.7139256 , 2.4607482 , 2.46525741, 2.43673253, 2.39470148]),\n",
       " 'score_time': array([0.08105874, 0.07805586, 0.07605433, 0.07905602, 0.07505345]),\n",
       " 'test_f1': array([0.35813953, 0.35730858, 0.36792453, 0.3685446 , 0.37641723]),\n",
       " 'test_roc_auc': array([0.77235912, 0.77015776, 0.77837787, 0.78274101, 0.77563957])}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(pipeline_modelo, X_t, y_train, cv=5, scoring=('f1', 'roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X9-EMQu7lh3K",
    "outputId": "a7e9f22f-b718-4437-abc4-d98b860061ea"
   },
   "outputs": [],
   "source": [
    "pipeline_modelo[1].feature_importances_    #No se entiende este "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "T8jk5Rxntf0F"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  warnings.warn(\"Given feature/column names or counts do not match \"\n"
     ]
    }
   ],
   "source": [
    "#Solo Pre-procesamiento\n",
    "train = pipeline_completo.fit_transform(X_t)\n",
    "val = pipeline_completo.transform(X_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IoX4R6tRtksM",
    "outputId": "2aff9ecc-7005-4f2f-afe9-3318f953abc1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:12:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=0,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb=xgb.XGBClassifier(seed=0)\n",
    "xgb.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ypy3Pojutpkb",
    "outputId": "dbdb394f-ab6c-4fdf-dc57-590fad720c1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MÉTRICAS CONJUNTO DE TRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     23390\n",
      "           1       0.90      0.42      0.58      2970\n",
      "\n",
      "    accuracy                           0.93     26360\n",
      "   macro avg       0.91      0.71      0.77     26360\n",
      "weighted avg       0.93      0.93      0.92     26360\n",
      "\n",
      "MÉTRICAS CONJUNTO DE VALIDACIÓN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.95      5848\n",
      "           1       0.62      0.27      0.38       742\n",
      "\n",
      "    accuracy                           0.90      6590\n",
      "   macro avg       0.77      0.63      0.66      6590\n",
      "weighted avg       0.88      0.90      0.88      6590\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"MÉTRICAS CONJUNTO DE TRAIN\")\n",
    "print(classification_report(y_train, xgb.predict(train)))\n",
    "print(\"MÉTRICAS CONJUNTO DE VALIDACIÓN\")\n",
    "print(classification_report(y_val, xgb.predict(val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "id": "R-tgUtUjttGu",
    "outputId": "3b827390-388f-44fb-888e-da7c6fb92b39"
   },
   "outputs": [],
   "source": [
    "#Optimización de hiperparámetros\n",
    "#Grilla de parámetros\n",
    "params={'objective':[\"binary:logistic\",\"binary:hinge\",\"binary:logitraw\"],\n",
    "        'learning_rate':[ 0.1,0.2,0.3],\n",
    "        'max_depth':[2,4, 6, 7, 8, 10],\n",
    "        'alpha':[2, 3, 5, 7],\n",
    "        \"n_estimators\":[5, 7, 10]\n",
    "       }\n",
    "xg=xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AmgQVk45uA2O",
    "outputId": "5a5d38f8-2d6a-400d-f8e5-e83d79d42188"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs...\n",
       "                                     num_parallel_tree=None, random_state=None,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, subsample=None,\n",
       "                                     tree_method=None, validate_parameters=None,\n",
       "                                     verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'alpha': [2, 3, 5, 7],\n",
       "                         'learning_rate': [0.1, 0.2, 0.3],\n",
       "                         'max_depth': [2, 4, 6, 7, 8, 10],\n",
       "                         'n_estimators': [5, 7, 10],\n",
       "                         'objective': ['binary:logistic', 'binary:hinge',\n",
       "                                       'binary:logitraw']},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Búsqueda de parámetros\n",
    "cv_xgb = GridSearchCV(xg, params, scoring='f1', cv=5,refit=True,n_jobs=-1)     \n",
    "cv_xgb.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Is2t9QDWuTgm",
    "outputId": "c190df5a-21ae-4745-8d5f-c71663e778d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 7,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 8,\n",
       " 'n_estimators': 10,\n",
       " 'objective': 'binary:hinge'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_xgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QGH0hI8XyRWr"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FHLpPG38uV73",
    "outputId": "6d8e949f-019c-45d1-fc6d-169199490881"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(alpha=7, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=8,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=10, n_jobs=4, num_parallel_tree=1,\n",
       "              objective='binary:hinge', random_state=0, reg_alpha=7,\n",
       "              reg_lambda=1, scale_pos_weight=None, seed=0, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamiento de la mejor versión encontrada del modelo\n",
    "xgb_best = xgb.XGBClassifier(seed=0, alpha= 7, learning_rate= 0.1, max_depth= 8, n_estimators=10, objective='binary:hinge')\n",
    "xgb_best.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VxVoKbFduX8x",
    "outputId": "1ff4e656-8026-4d71-ec8c-252cd5b516ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MÉTRICAS CONJUNTO DE TRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93     23390\n",
      "           1       0.44      0.56      0.49      2970\n",
      "\n",
      "    accuracy                           0.87     26360\n",
      "   macro avg       0.69      0.73      0.71     26360\n",
      "weighted avg       0.89      0.87      0.88     26360\n",
      "\n",
      "MÉTRICAS CONJUNTO DE VALIDACIÓN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93      5848\n",
      "           1       0.44      0.57      0.49       742\n",
      "\n",
      "    accuracy                           0.87      6590\n",
      "   macro avg       0.69      0.74      0.71      6590\n",
      "weighted avg       0.89      0.87      0.88      6590\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"MÉTRICAS CONJUNTO DE TRAIN\")\n",
    "print(classification_report(y_train, xgb_best.predict(train)))\n",
    "print(\"MÉTRICAS CONJUNTO DE VALIDACIÓN\")\n",
    "print(classification_report(y_val, xgb_best.predict(val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimización de hiperparámetros\n",
    "#Grilla de parámetros\n",
    "params={'objective':[\"binary:logistic\",\"binary:hinge\",\"binary:logitraw\"],\n",
    "        'learning_rate':[0.05,0.1,0.15,0.2,0.25,0.3,0.4,0.5],\n",
    "        'max_depth':[2,3, 4,5, 6, 7, 8, 9, 10, 12, 15],\n",
    "        'alpha':[0, 0.5, 1, 2, 3, 5, 6, 7, 8, 9, 10],\n",
    "        'lambda':[0.5, 1, 2, 3, 5],\n",
    "        \"n_estimators\":[3, 5, 6, 7, 8, 9, 10, 15],\n",
    "        \"booster\":[\"gbtree\",\"dart\"],\n",
    "        \"gamma\":[0.5,1,2,5, 7, 8],\n",
    "        \"tree_method\":[\"auto\",\"exact\",\"approx\",\"hist\"]\n",
    "       }\n",
    "xg=xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Búsqueda de parámetros\n",
    "rcv_xgb = RandomizedSearchCV(xg, params, scoring='f1', cv=5,refit=True,n_jobs=-1)     \n",
    "rcv_xgb.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcv_xgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrenamiento de la mejor versión encontrada del modelo\n",
    "xgb_best_r = xgb.XGBClassifier(seed=0, tree_method= 'approx', objective=\"binary:hinge\", n_estimators=3, max_depth= 6,\n",
    "                               learning_rate= 0.25, reg_lambda=3, gamma= 8, booster=\"dart\", \n",
    "                               alpha= 0 )   #el lambda por default es 1\n",
    "xgb_best_r.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MÉTRICAS CONJUNTO DE TRAIN\")\n",
    "print(classification_report(y_train, xgb_best_r.predict(train)))\n",
    "print(\"MÉTRICAS CONJUNTO DE VALIDACIÓN\")\n",
    "print(classification_report(y_val, xgb_best_r.predict(val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yZGVwR3Rbdbv"
   },
   "source": [
    "### LigthGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "34o1JZ_0ibuE"
   },
   "outputs": [],
   "source": [
    "variables_categoricas = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'poutcome']\n",
    "variables_numericas = ['age', 'campaign', 'previous', 'cons.conf.idx', 'euribor3m']\n",
    "\n",
    "# Filtramos las variables que seleccionamos\n",
    "X_t = X_train[variables_categoricas + variables_numericas]\n",
    "\n",
    "pipeline_numerico = Pipeline([('select_numeric_columns', SelectColumnsTransformer(variables_numericas)),\n",
    "                             # ('standard_scaler', StandardScaler()),\n",
    "                             # (\"kbins_discretizer\", KBinsDiscretizer(n_bins=5, encode=\"ordinal\", strategy=\"quantile\"))      #strategy=\"uniform\"\n",
    "                            ])\n",
    "\n",
    "pipeline_categorico = Pipeline ([('select_categoric_columns', SelectColumnsTransformer(variables_categoricas)),\n",
    "                                 # ('imputer', SimpleImputer(strategy='most_frequent', missing_values=\"unknown\")),      #podríamos no ponerlo, y que deje \"desconocido\" como una categoría más\n",
    "                                 ('cat', OneHotEncoder())])\n",
    "\n",
    "pipeline_completo = ColumnTransformer([('num', pipeline_numerico, variables_numericas),\n",
    "                                   ('cat', pipeline_categorico, variables_categoricas),\n",
    "                                  ])\n",
    "\n",
    "pipeline_modelo = Pipeline([('preprocess', pipeline_completo),\n",
    "                            ('lgbm', lgbm(seed=0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A_U0Jpw7iw53"
   },
   "outputs": [],
   "source": [
    "pipeline_modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pCZZ_xSfiz-F"
   },
   "outputs": [],
   "source": [
    "cross_validate(pipeline_modelo, X_t, y_train, cv=5, scoring=('f1', 'roc_auc', \"precision\", \"recall\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba con las variables del PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos el dataset con la función de pandas \"read_csv\"\n",
    "key = \"data/final_df.csv\"\n",
    "df_pca = pd.read_csv(key, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = df_pca.drop(columns=['Unnamed: 0', 'Unnamed: 0.1', 'age', 'job', 'marital', 'education',\n",
    "       'default', 'housing', 'loan', 'contact', 'month', 'day_of_week',\n",
    "       'campaign', 'pdays', 'previous', 'poutcome', 'emp.var.rate',\n",
    "       'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed', 'y',\n",
    "       'job_num', 'marital_num', 'education_num', 'loan_num', 'housing_num',\n",
    "       'default_num'])\n",
    "y_pca = df_pca.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca_temp, X_pca_test, y_pca_temp, y_pca_test = train_test_split(X_pca, y_pca, test_size=0.2, stratify=y, random_state=42) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probando XGBoost con distintas variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Todas las variables del dataset\n",
    "variables_categoricas_original = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome']\n",
    "variables_numericas_original = ['age', 'campaign', 'previous','emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Todas las variables del dataset menos pdays y duration, que se definió que no debían estar\n",
    "variables_categoricas = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome']\n",
    "variables_numericas = ['age', 'campaign', 'previous','emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtramos las variables que seleccionamos\n",
    "X_t = X_train[variables_categoricas + variables_numericas]\n",
    "X_v = X_val[variables_categoricas + variables_numericas]\n",
    "\n",
    "pipeline_numerico = Pipeline([('select_numeric_columns', SelectColumnsTransformer(variables_numericas)),\n",
    "                             # ('standard_scaler', StandardScaler()),\n",
    "                             # (\"kbins_discretizer\", KBinsDiscretizer(n_bins=5, encode=\"ordinal\", strategy=\"quantile\"))      #strategy=\"uniform\"\n",
    "                            ])\n",
    "\n",
    "pipeline_categorico = Pipeline ([('select_categoric_columns', SelectColumnsTransformer(variables_categoricas)),\n",
    "                                 #('imputer', SimpleImputer(strategy='most_frequent', missing_values=\"unknown\")),      #podríamos no ponerlo, y que deje \"desconocido\" como una categoría más\n",
    "                                 ('cat', OneHotEncoder())])\n",
    "\n",
    "pipeline_completo = ColumnTransformer([('num', pipeline_numerico, variables_numericas),\n",
    "                                   ('cat', pipeline_categorico, variables_categoricas),\n",
    "                                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solo Pre-procesamiento\n",
    "train = pipeline_completo.fit_transform(X_t)\n",
    "val = pipeline_completo.transform(X_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:29:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=0,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_var=xgb.XGBClassifier(seed=0)\n",
    "xgb_var.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MÉTRICAS CONJUNTO DE TRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96     23390\n",
      "           1       0.92      0.45      0.60      2970\n",
      "\n",
      "    accuracy                           0.93     26360\n",
      "   macro avg       0.93      0.72      0.78     26360\n",
      "weighted avg       0.93      0.93      0.92     26360\n",
      "\n",
      "MÉTRICAS CONJUNTO DE VALIDACIÓN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94      5848\n",
      "           1       0.61      0.27      0.38       742\n",
      "\n",
      "    accuracy                           0.90      6590\n",
      "   macro avg       0.76      0.63      0.66      6590\n",
      "weighted avg       0.88      0.90      0.88      6590\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"MÉTRICAS CONJUNTO DE TRAIN\")\n",
    "print(classification_report(y_train, xgb_var.predict(train)))\n",
    "print(\"MÉTRICAS CONJUNTO DE VALIDACIÓN\")\n",
    "print(classification_report(y_val, xgb_var.predict(val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saco las variables de contexto que estaban muy correlacionadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Todas las variables del dataset menos pdays y duration, menos las de contexto que estaban muy correlacionadas\n",
    "variables_categoricas = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome']\n",
    "variables_numericas = ['age', 'campaign', 'previous', 'cons.conf.idx', 'euribor3m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtramos las variables que seleccionamos\n",
    "X_t = X_train[variables_categoricas + variables_numericas]\n",
    "X_v = X_val[variables_categoricas + variables_numericas]\n",
    "\n",
    "pipeline_numerico = Pipeline([('select_numeric_columns', SelectColumnsTransformer(variables_numericas)),\n",
    "                             # ('standard_scaler', StandardScaler()),\n",
    "                             # (\"kbins_discretizer\", KBinsDiscretizer(n_bins=5, encode=\"ordinal\", strategy=\"quantile\"))      #strategy=\"uniform\"\n",
    "                            ])\n",
    "\n",
    "pipeline_categorico = Pipeline ([('select_categoric_columns', SelectColumnsTransformer(variables_categoricas)),\n",
    "                                 #('imputer', SimpleImputer(strategy='most_frequent', missing_values=\"unknown\")),      #podríamos no ponerlo, y que deje \"desconocido\" como una categoría más\n",
    "                                 ('cat', OneHotEncoder())])\n",
    "\n",
    "pipeline_completo = ColumnTransformer([('num', pipeline_numerico, variables_numericas),\n",
    "                                   ('cat', pipeline_categorico, variables_categoricas),\n",
    "                                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solo Pre-procesamiento\n",
    "train = pipeline_completo.fit_transform(X_t)\n",
    "val = pipeline_completo.transform(X_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:30:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=0,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_var=xgb.XGBClassifier(seed=0)\n",
    "xgb_var.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MÉTRICAS CONJUNTO DE TRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     23390\n",
      "           1       0.90      0.43      0.58      2970\n",
      "\n",
      "    accuracy                           0.93     26360\n",
      "   macro avg       0.91      0.71      0.77     26360\n",
      "weighted avg       0.93      0.93      0.92     26360\n",
      "\n",
      "MÉTRICAS CONJUNTO DE VALIDACIÓN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94      5848\n",
      "           1       0.60      0.26      0.37       742\n",
      "\n",
      "    accuracy                           0.90      6590\n",
      "   macro avg       0.76      0.62      0.66      6590\n",
      "weighted avg       0.88      0.90      0.88      6590\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"MÉTRICAS CONJUNTO DE TRAIN\")\n",
    "print(classification_report(y_train, xgb_var.predict(train)))\n",
    "print(\"MÉTRICAS CONJUNTO DE VALIDACIÓN\")\n",
    "print(classification_report(y_val, xgb_var.predict(val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ver otras combinaciones de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Todas las variables del dataset menos pdays y duration, menos las de contexto que estaban muy correlacionadas\n",
    "#saqué month, luego default (volvió al resultado mejor), saco housing (mejoró), \n",
    "#saco previous (empeora)\n",
    "#saco loan (empeora)\n",
    "#saco marital (queda igual)\n",
    "#saco day_of_week (empeora)\n",
    "#saco education (empeora)\n",
    "#saco job (empeora)\n",
    "#saco contact (empeora poquito)\n",
    "#saco poutcome (empeora poquito)\n",
    "#saco campaign (empeora poquito)\n",
    "#saco cons idx (empeora poquito)   \n",
    "\n",
    "variables_categoricas = ['job', 'education', 'contact','loan', 'day_of_week', 'poutcome']\n",
    "variables_numericas = ['age', 'campaign','previous', 'cons.conf.idx', 'euribor3m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtramos las variables que seleccionamos\n",
    "X_t = X_train[variables_categoricas + variables_numericas]\n",
    "X_v = X_val[variables_categoricas + variables_numericas]\n",
    "\n",
    "pipeline_numerico = Pipeline([('select_numeric_columns', SelectColumnsTransformer(variables_numericas)),\n",
    "                             # ('standard_scaler', StandardScaler()),\n",
    "                             # (\"kbins_discretizer\", KBinsDiscretizer(n_bins=5, encode=\"ordinal\", strategy=\"quantile\"))      #strategy=\"uniform\"\n",
    "                            ])\n",
    "\n",
    "pipeline_categorico = Pipeline ([('select_categoric_columns', SelectColumnsTransformer(variables_categoricas)),\n",
    "                                 #('imputer', SimpleImputer(strategy='most_frequent', missing_values=\"unknown\")),      #podríamos no ponerlo, y que deje \"desconocido\" como una categoría más\n",
    "                                 ('cat', OneHotEncoder())])\n",
    "\n",
    "pipeline_completo = ColumnTransformer([('num', pipeline_numerico, variables_numericas),\n",
    "                                   ('cat', pipeline_categorico, variables_categoricas),\n",
    "                                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solo Pre-procesamiento\n",
    "train = pipeline_completo.fit_transform(X_t)\n",
    "val = pipeline_completo.transform(X_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:28:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=0,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_var=xgb.XGBClassifier(seed=0)\n",
    "xgb_var.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MÉTRICAS CONJUNTO DE TRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     23390\n",
      "           1       0.85      0.41      0.55      2970\n",
      "\n",
      "    accuracy                           0.93     26360\n",
      "   macro avg       0.89      0.70      0.76     26360\n",
      "weighted avg       0.92      0.93      0.91     26360\n",
      "\n",
      "MÉTRICAS CONJUNTO DE VALIDACIÓN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94      5848\n",
      "           1       0.54      0.25      0.34       742\n",
      "\n",
      "    accuracy                           0.89      6590\n",
      "   macro avg       0.73      0.61      0.64      6590\n",
      "weighted avg       0.87      0.89      0.87      6590\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"MÉTRICAS CONJUNTO DE TRAIN\")\n",
    "print(classification_report(y_train, xgb_var.predict(train)))\n",
    "print(\"MÉTRICAS CONJUNTO DE VALIDACIÓN\")\n",
    "print(classification_report(y_val, xgb_var.predict(val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimización de parámetros considerando la mejor combinación de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_categoricas = ['job', 'education', 'contact','loan', 'day_of_week', 'poutcome']\n",
    "variables_numericas = ['age', 'campaign','previous', 'cons.conf.idx', 'euribor3m']\n",
    "\n",
    "# Filtramos las variables que seleccionamos\n",
    "X_t = X_train[variables_categoricas + variables_numericas]\n",
    "X_v = X_val[variables_categoricas + variables_numericas]\n",
    "\n",
    "pipeline_numerico = Pipeline([('select_numeric_columns', SelectColumnsTransformer(variables_numericas)),\n",
    "                             # ('standard_scaler', StandardScaler()),\n",
    "                             # (\"kbins_discretizer\", KBinsDiscretizer(n_bins=5, encode=\"ordinal\", strategy=\"quantile\"))      #strategy=\"uniform\"\n",
    "                            ])\n",
    "\n",
    "pipeline_categorico = Pipeline ([('select_categoric_columns', SelectColumnsTransformer(variables_categoricas)),\n",
    "                                 #('imputer', SimpleImputer(strategy='most_frequent', missing_values=\"unknown\")),      #podríamos no ponerlo, y que deje \"desconocido\" como una categoría más\n",
    "                                 ('cat', OneHotEncoder())])\n",
    "\n",
    "pipeline_completo = ColumnTransformer([('num', pipeline_numerico, variables_numericas),\n",
    "                                   ('cat', pipeline_categorico, variables_categoricas),\n",
    "                                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solo Pre-procesamiento\n",
    "train = pipeline_completo.fit_transform(X_t)\n",
    "val = pipeline_completo.transform(X_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimización de hiperparámetros\n",
    "#Grilla de parámetros\n",
    "params={'objective':[\"binary:logistic\",\"binary:hinge\",\"binary:logitraw\"],\n",
    "        'learning_rate':[ 0.1,0.2,0.3],\n",
    "        'max_depth':[2,4, 6, 7, 8, 10],\n",
    "        'alpha':[2, 3, 5, 7],\n",
    "        \"n_estimators\":[5, 7, 10]\n",
    "       }\n",
    "xg=xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs...\n",
       "                                     num_parallel_tree=None, random_state=None,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, subsample=None,\n",
       "                                     tree_method=None, validate_parameters=None,\n",
       "                                     verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'alpha': [2, 3, 5, 7],\n",
       "                         'learning_rate': [0.1, 0.2, 0.3],\n",
       "                         'max_depth': [2, 4, 6, 7, 8, 10],\n",
       "                         'n_estimators': [5, 7, 10],\n",
       "                         'objective': ['binary:logistic', 'binary:hinge',\n",
       "                                       'binary:logitraw']},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Búsqueda de parámetros\n",
    "cv_xgb = GridSearchCV(xg, params, scoring='f1', cv=5,refit=True,n_jobs=-1)     \n",
    "cv_xgb.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 7,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 8,\n",
       " 'n_estimators': 10,\n",
       " 'objective': 'binary:hinge'}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_xgb.best_params_   ### no es muy distinto al mejor modelo encontrado con la otra especificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(alpha=7, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=8,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=10, n_jobs=4, num_parallel_tree=1,\n",
       "              objective='binary:hinge', random_state=0, reg_alpha=7,\n",
       "              reg_lambda=1, scale_pos_weight=None, seed=0, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamiento de la mejor versión encontrada del modelo\n",
    "xgb_best = xgb.XGBClassifier(seed=0, alpha= 7, learning_rate= 0.1, max_depth= 8, n_estimators=10, objective='binary:hinge')\n",
    "xgb_best.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MÉTRICAS CONJUNTO DE TRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93     23390\n",
      "           1       0.44      0.56      0.49      2970\n",
      "\n",
      "    accuracy                           0.87     26360\n",
      "   macro avg       0.69      0.73      0.71     26360\n",
      "weighted avg       0.89      0.87      0.88     26360\n",
      "\n",
      "MÉTRICAS CONJUNTO DE VALIDACIÓN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93      5848\n",
      "           1       0.44      0.56      0.49       742\n",
      "\n",
      "    accuracy                           0.87      6590\n",
      "   macro avg       0.69      0.74      0.71      6590\n",
      "weighted avg       0.89      0.87      0.88      6590\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"MÉTRICAS CONJUNTO DE TRAIN\")\n",
    "print(classification_report(y_train, xgb_best.predict(train)))\n",
    "print(\"MÉTRICAS CONJUNTO DE VALIDACIÓN\")\n",
    "print(classification_report(y_val, xgb_best.predict(val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature explainability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_categoricas = ['job', 'education', 'contact','loan', 'day_of_week', 'poutcome']\n",
    "variables_numericas = ['age', 'campaign','previous', 'cons.conf.idx', 'euribor3m']\n",
    "\n",
    "# Filtramos las variables que seleccionamos\n",
    "X_t = X_train[variables_categoricas + variables_numericas]\n",
    "X_v = X_val[variables_categoricas + variables_numericas]\n",
    "\n",
    "pipeline_numerico = Pipeline([('select_numeric_columns', SelectColumnsTransformer(variables_numericas)),\n",
    "                             # ('standard_scaler', StandardScaler()),\n",
    "                             # (\"kbins_discretizer\", KBinsDiscretizer(n_bins=5, encode=\"ordinal\", strategy=\"quantile\"))      #strategy=\"uniform\"\n",
    "                            ])\n",
    "\n",
    "pipeline_categorico = Pipeline ([('select_categoric_columns', SelectColumnsTransformer(variables_categoricas)),\n",
    "                                 #('imputer', SimpleImputer(strategy='most_frequent', missing_values=\"unknown\")),      #podríamos no ponerlo, y que deje \"desconocido\" como una categoría más\n",
    "                                 ('cat', OneHotEncoder())])\n",
    "\n",
    "pipeline_completo = ColumnTransformer([('num', pipeline_numerico, variables_numericas),\n",
    "                                   ('cat', pipeline_categorico, variables_categoricas),\n",
    "                                  ])\n",
    "\n",
    "pipeline_modelo = Pipeline([('preprocess', pipeline_completo),\n",
    "                            ('xgb', xgb.XGBClassifier(seed=0, alpha= 7, learning_rate= 0.1, max_depth= 8, n_estimators=10, objective='binary:hinge'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocess',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('select_numeric_columns',\n",
       "                                                                   <__main__.SelectColumnsTransformer object at 0x00000094EBADFAC0>)]),\n",
       "                                                  ['age', 'campaign',\n",
       "                                                   'previous', 'cons.conf.idx',\n",
       "                                                   'euribor3m']),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('select_categoric_columns',\n",
       "                                                                   <__main__.SelectColumnsTransformer object at 0x00000094EB834DC0>),\n",
       "                                                                  (...\n",
       "                               importance_type='gain',\n",
       "                               interaction_constraints='', learning_rate=0.1,\n",
       "                               max_delta_step=0, max_depth=8,\n",
       "                               min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=10,\n",
       "                               n_jobs=4, num_parallel_tree=1,\n",
       "                               objective='binary:hinge', random_state=0,\n",
       "                               reg_alpha=7, reg_lambda=1, scale_pos_weight=None,\n",
       "                               seed=0, subsample=1, tree_method='exact',\n",
       "                               validate_parameters=1, verbosity=None))])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_modelo.fit(X_t, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pipeline_completo.transform(X_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26360, 38)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtener los nombres de las variables\n",
    "# Si realizamos one hot encoding, vamos a tener el problema de que se incrementan el numero de features y necesitamos la nueva lista.\n",
    "numeric_features = variables_numericas\n",
    "cat_features = pipeline_modelo.named_steps['preprocess'].transformers_[1][1].get_feature_names(variables_categoricas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_columns = np.array(cat_features)\n",
    "numeric_features_list = np.array(numeric_features)\n",
    "numeric_features_list = np.append(numeric_features_list, onehot_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Es necesario ordenar las los valores del feature importance (utilizamos argsort para tener el orden de los indices)\n",
    "sorted_idx = pipeline_modelo[1].feature_importances_.argsort()\n",
    "plt.barh(numeric_features_list[sorted_idx], pipeline_modelo[1].feature_importances_[sorted_idx])\n",
    "plt.xlabel(\"Xgboost Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting eli5\n",
      "  Downloading eli5-0.11.0-py2.py3-none-any.whl (106 kB)\n",
      "Requirement already satisfied: graphviz in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from eli5) (0.17)\n",
      "Requirement already satisfied: scikit-learn>=0.20 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from eli5) (0.23.2)\n",
      "Requirement already satisfied: six in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from eli5) (1.15.0)\n",
      "Requirement already satisfied: attrs>16.0.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from eli5) (20.3.0)\n",
      "Requirement already satisfied: numpy>=1.9.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from eli5) (1.19.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from eli5) (1.5.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from eli5) (2.11.2)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from eli5) (0.8.9)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20->eli5) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20->eli5) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from jinja2->eli5) (1.1.1)\n",
      "Installing collected packages: eli5\n",
      "Successfully installed eli5-0.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probando la otra alternativa\n",
    "import eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_columns = cat_features          #depende de paso anterior que no salió\n",
    "features_list = list(numeric_features)\n",
    "features_list.extend(onehot_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-165-dd666da19d08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0meli5\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplain_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline_modelo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\functools.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    873\u001b[0m                             '1 positional argument')\n\u001b[0;32m    874\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 875\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    876\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m     \u001b[0mfuncname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__name__'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'singledispatch function'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\eli5\\xgboost.py\u001b[0m in \u001b[0;36mexplain_weights_xgboost\u001b[1;34m(xgb, vec, top, target_names, targets, feature_names, feature_re, feature_filter, importance_type)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[0mbooster\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_regression\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_booster_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mxgb_feature_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[0mcoef\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_xgb_feature_importances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimportance_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimportance_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     return get_feature_importance_explanation(\n\u001b[0;32m     74\u001b[0m         \u001b[0mxgb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\eli5\\xgboost.py\u001b[0m in \u001b[0;36m_xgb_feature_importances\u001b[1;34m(booster, importance_type)\u001b[0m\n\u001b[0;32m    329\u001b[0m     \u001b[0mfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimportance_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimportance_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m     all_features = np.array(\n\u001b[1;32m--> 331\u001b[1;33m         [fs.get(f, 0.) for f in booster.feature_names], dtype=np.float32)\n\u001b[0m\u001b[0;32m    332\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mall_features\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mall_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "eli5.explain_weights(pipeline_modelo[1], top=50, feature_names=features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **LGBM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-49932eaa8753>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Filtramos las variables que seleccionamos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mX_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvariables_categoricas\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mvariables_numericas\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mX_v\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvariables_categoricas\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mvariables_numericas\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "##Pre-procesamiento sobre los conjuntos de Train y Validation\n",
    "variables_categoricas = ['job', 'marital','education','housing', 'loan','contact','poutcome']\n",
    "variables_numericas = ['age', 'campaign','previous','euribor3m','cons.conf.idx' ]\n",
    "\n",
    "# Filtramos las variables que seleccionamos\n",
    "X_t = X_train[variables_categoricas + variables_numericas]\n",
    "X_v = X_val[variables_categoricas + variables_numericas]\n",
    "\n",
    "pipeline_numerico = Pipeline([('select_numeric_columns', SelectColumnsTransformer(variables_numericas)),\n",
    "                             ('standard_scaler', StandardScaler()),\n",
    "                             #('pca', PCA(n_components=4))\n",
    "                            ])\n",
    "\n",
    "pipeline_categorico = Pipeline ([('imputer', SimpleImputer(strategy='most_frequent', missing_values = None)),\n",
    "                                   ('cat', OneHotEncoder())])\n",
    "\n",
    "pipeline_completo = ColumnTransformer([('num', pipeline_numerico, variables_numericas),\n",
    "                                       ('cat', pipeline_categorico, variables_categoricas)\n",
    "                                      ])\n",
    "\n",
    "train = pipeline_completo.fit_transform(X_t)\n",
    "val = pipeline_completo.fit_transform(X_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_clf = lgbm.LGBMClassifier()\n",
    "lgb_clf.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MÉTRICAS CONJUNTO DE TRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95     23390\n",
      "           1       0.78      0.33      0.46      2970\n",
      "\n",
      "    accuracy                           0.91     26360\n",
      "   macro avg       0.85      0.66      0.71     26360\n",
      "weighted avg       0.91      0.91      0.90     26360\n",
      "\n",
      "MÉTRICAS CONJUNTO DE VALIDACIÓN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94      5848\n",
      "           1       0.62      0.24      0.34       742\n",
      "\n",
      "    accuracy                           0.90      6590\n",
      "   macro avg       0.77      0.61      0.64      6590\n",
      "weighted avg       0.88      0.90      0.88      6590\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"MÉTRICAS CONJUNTO DE TRAIN\")\n",
    "print(classification_report(y_train, lgb_clf.predict(train)))\n",
    "print(\"MÉTRICAS CONJUNTO DE VALIDACIÓN\")\n",
    "print(classification_report(y_val, lgb_clf.predict(val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(class_weight='balanced', objective='binary')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_clf = lgbm.LGBMClassifier(objective=\"binary\", class_weight=\"balanced\")\n",
    "lgb_clf.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MÉTRICAS CONJUNTO DE TRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91     23390\n",
      "           1       0.41      0.70      0.51      2970\n",
      "\n",
      "    accuracy                           0.85     26360\n",
      "   macro avg       0.68      0.79      0.71     26360\n",
      "weighted avg       0.90      0.85      0.87     26360\n",
      "\n",
      "MÉTRICAS CONJUNTO DE VALIDACIÓN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.85      0.89      5848\n",
      "           1       0.34      0.64      0.45       742\n",
      "\n",
      "    accuracy                           0.82      6590\n",
      "   macro avg       0.65      0.74      0.67      6590\n",
      "weighted avg       0.88      0.82      0.84      6590\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"MÉTRICAS CONJUNTO DE TRAIN\")\n",
    "print(classification_report(y_train, lgb_clf.predict(train)))\n",
    "print(\"MÉTRICAS CONJUNTO DE VALIDACIÓN\")\n",
    "print(classification_report(y_val, lgb_clf.predict(val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimización de hiperparámetros\n",
    "#Grilla de parámetros\n",
    "params={'boosting_type':[\"gbdt\",\"dart\",\"goss\",\"rf\"],\n",
    "        'learning_rate':[ 0.1,0.2,0.3,0.5,0.7,0.8,1],\n",
    "        'max_depth':[1,2,4, 6, 7, 8, 10],\n",
    "        'reg_alpha':[0, 2, 3, 5],\n",
    "        \"n_estimators\":[5, 7, 10, 50, 100, 200, 500]\n",
    "       }\n",
    "lgb_clf = lgbm.LGBMClassifier(objective=\"binary\", class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=LGBMClassifier(class_weight='balanced',\n",
       "                                      objective='binary'),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'boosting_type': ['gbdt', 'dart', 'goss', 'rf'],\n",
       "                         'learning_rate': [0.1, 0.2, 0.3, 0.5, 0.7, 0.8, 1],\n",
       "                         'max_depth': [1, 2, 4, 6, 7, 8, 10],\n",
       "                         'n_estimators': [5, 7, 10, 50, 100, 200, 500],\n",
       "                         'reg_alpha': [0, 2, 3, 5]},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Búsqueda de parámetros\n",
    "cv_lgb = GridSearchCV(lgb_clf, params, scoring='f1', cv=5,refit=True,n_jobs=-1)     \n",
    "cv_lgb.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'dart',\n",
       " 'learning_rate': 0.2,\n",
       " 'max_depth': 8,\n",
       " 'n_estimators': 100,\n",
       " 'reg_alpha': 3}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_lgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Pre-procesamiento sobre los conjuntos de Train y Validation\n",
    "variables_categoricas = ['job', 'marital','education','housing', 'loan','contact','poutcome']\n",
    "variables_numericas= ['age', 'campaign', 'previous','emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
    "\n",
    "# Filtramos las variables que seleccionamos\n",
    "X_t = X_train[variables_categoricas + variables_numericas]\n",
    "X_v = X_val[variables_categoricas + variables_numericas]\n",
    "\n",
    "pipeline_numerico = Pipeline([('select_numeric_columns', SelectColumnsTransformer(variables_numericas)),\n",
    "                             ('standard_scaler', StandardScaler()),\n",
    "                             ('pca', PCA(n_components=4))\n",
    "                            ])\n",
    "\n",
    "pipeline_categorico = Pipeline ([('imputer', SimpleImputer(strategy='most_frequent', missing_values = None)),\n",
    "                                   ('cat', OneHotEncoder())])\n",
    "\n",
    "pipeline_completo = ColumnTransformer([('num', pipeline_numerico, variables_numericas),\n",
    "                                       ('cat', pipeline_categorico, variables_categoricas)\n",
    "                                      ])\n",
    "\n",
    "train = pipeline_completo.fit_transform(X_t)\n",
    "val = pipeline_completo.fit_transform(X_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='dart', class_weight='balanced', learning_rate=0.2,\n",
       "               max_depth=8, objective='binary', reg_alpha=3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamiento de la mejor versión encontrada del modelo\n",
    "lgb_best= lgbm.LGBMClassifier(objective=\"binary\", class_weight=\"balanced\", boosting_type= 'dart',\n",
    "                     learning_rate= 0.2, max_depth= 8, n_estimators= 100, reg_alpha= 3 )\n",
    "lgb_best.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MÉTRICAS CONJUNTO DE TRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.86      0.91     22715\n",
      "           1       0.40      0.70      0.51      2945\n",
      "\n",
      "    accuracy                           0.85     25660\n",
      "   macro avg       0.68      0.78      0.71     25660\n",
      "weighted avg       0.89      0.85      0.86     25660\n",
      "\n",
      "MÉTRICAS CONJUNTO DE VALIDACIÓN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.74      0.83      5679\n",
      "           1       0.24      0.64      0.35       736\n",
      "\n",
      "    accuracy                           0.73      6415\n",
      "   macro avg       0.59      0.69      0.59      6415\n",
      "weighted avg       0.86      0.73      0.77      6415\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"MÉTRICAS CONJUNTO DE TRAIN\")\n",
    "print(classification_report(y_train, lgb_best.predict(train)))\n",
    "print(\"MÉTRICAS CONJUNTO DE VALIDACIÓN\")\n",
    "print(classification_report(y_val, lgb_best.predict(val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Pre-procesamiento sobre los conjuntos de Train y Validation\n",
    "variables_categoricas = ['job', 'marital','education','housing', 'loan','contact','poutcome']\n",
    "variables_numericas= ['age', 'campaign', 'previous','emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
    "\n",
    "# Filtramos las variables que seleccionamos\n",
    "X_t = X_train[variables_categoricas + variables_numericas]\n",
    "X_v = X_val[variables_categoricas + variables_numericas]\n",
    "\n",
    "pipeline_numerico = Pipeline([('select_numeric_columns', SelectColumnsTransformer(variables_numericas)),\n",
    "                             ('standard_scaler', StandardScaler()),\n",
    "                             ('pca', PCA(n_components=4))\n",
    "                            ])\n",
    "\n",
    "pipeline_categorico = Pipeline ([('imputer', SimpleImputer(strategy='most_frequent', missing_values = None)),\n",
    "                                   ('cat', OneHotEncoder())])\n",
    "\n",
    "pipeline_completo = ColumnTransformer([('num', pipeline_numerico, variables_numericas),\n",
    "                                       ('cat', pipeline_categorico, variables_categoricas)\n",
    "                                      ])\n",
    "\n",
    "train = pipeline_completo.fit_transform(X_t)\n",
    "val = pipeline_completo.fit_transform(X_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#bagging = BaggingClassifier(KNeighborsClassifier(),max_samples=0.5, max_features=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=BaggingClassifier(base_estimator=KNeighborsClassifier(),\n",
       "                                               random_state=42),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'base_estimator__algorithm': ['ball_tree',\n",
       "                                                                      'kd_tree',\n",
       "                                                                      'brute'],\n",
       "                                        'base_estimator__n_neighbors': [4, 5, 6,\n",
       "                                                                        7, 10],\n",
       "                                        'base_estimator__p': [1, 2],\n",
       "                                        'base_estimator__weights': ['uniform',\n",
       "                                                                    'distance'],\n",
       "                                        'max_features': [0.5, 0.6, 0.7, 0.8,\n",
       "                                                         0.9],\n",
       "                                        'max_samples': [0.5, 0.6, 0.7, 0.8],\n",
       "                                        'n_estimators': [10, 50, 100, 200]},\n",
       "                   scoring='f1')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "search_params = {\n",
    "'base_estimator__n_neighbors' : [4,5,6,7, 10],\n",
    "'base_estimator__weights': ['uniform', 'distance'],\n",
    "'base_estimator__algorithm': ['ball_tree', 'kd_tree', 'brute'],\n",
    "'base_estimator__p': [1,2],\n",
    "'n_estimators' : [10, 50, 100, 200],\n",
    "'max_samples' : [ 0.5, 0.6, 0.7,0.8],\n",
    "'max_features': [0.5, 0.6,0.7,0.8,0.9]\n",
    "}\n",
    "\n",
    "bagging_clf = RandomizedSearchCV(BaggingClassifier(KNeighborsClassifier(), random_state = 42), search_params, cv=5, scoring='f1', n_jobs=-1)\n",
    "bagging_clf.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 10,\n",
       " 'max_samples': 0.8,\n",
       " 'max_features': 0.8,\n",
       " 'base_estimator__weights': 'distance',\n",
       " 'base_estimator__p': 2,\n",
       " 'base_estimator__n_neighbors': 5,\n",
       " 'base_estimator__algorithm': 'brute'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=KNeighborsClassifier(), max_features=0.8,\n",
       "                  max_samples=0.8, random_state=42)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging_clf_best= BaggingClassifier(KNeighborsClassifier(), n_estimators= 10, max_samples= 0.8,\n",
    "                 max_features= 0.8,random_state = 42)\n",
    "bagging_clf_best.fit(train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MÉTRICAS CONJUNTO DE TRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95     22715\n",
      "           1       0.79      0.30      0.44      2945\n",
      "\n",
      "    accuracy                           0.91     25660\n",
      "   macro avg       0.85      0.65      0.69     25660\n",
      "weighted avg       0.90      0.91      0.89     25660\n",
      "\n",
      "MÉTRICAS CONJUNTO DE VALIDACIÓN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94      5679\n",
      "           1       0.56      0.19      0.28       736\n",
      "\n",
      "    accuracy                           0.89      6415\n",
      "   macro avg       0.73      0.58      0.61      6415\n",
      "weighted avg       0.86      0.89      0.87      6415\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"MÉTRICAS CONJUNTO DE TRAIN\")\n",
    "print(classification_report(y_train, bagging_clf_best.predict(train)))\n",
    "print(\"MÉTRICAS CONJUNTO DE VALIDACIÓN\")\n",
    "print(classification_report(y_val, bagging_clf_best.predict(val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=KNeighborsClassifier(algorithm='brute',\n",
       "                                                      weights='distance'),\n",
       "                  max_features=0.8, max_samples=0.8, random_state=42)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging_clf_best= BaggingClassifier(KNeighborsClassifier(weights= 'distance', p=2,n_neighbors=5, algorithm=\"brute\"), n_estimators= 10, max_samples= 0.8,\n",
    "                 max_features= 0.8,random_state = 42)\n",
    "bagging_clf_best.fit(train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MÉTRICAS CONJUNTO DE TRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99     22715\n",
      "           1       0.98      0.81      0.88      2945\n",
      "\n",
      "    accuracy                           0.98     25660\n",
      "   macro avg       0.98      0.90      0.94     25660\n",
      "weighted avg       0.98      0.98      0.97     25660\n",
      "\n",
      "MÉTRICAS CONJUNTO DE VALIDACIÓN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94      5679\n",
      "           1       0.53      0.20      0.29       736\n",
      "\n",
      "    accuracy                           0.89      6415\n",
      "   macro avg       0.72      0.59      0.61      6415\n",
      "weighted avg       0.86      0.89      0.86      6415\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"MÉTRICAS CONJUNTO DE TRAIN\")\n",
    "print(classification_report(y_train, bagging_clf_best.predict(train)))\n",
    "print(\"MÉTRICAS CONJUNTO DE VALIDACIÓN\")\n",
    "print(classification_report(y_val, bagging_clf_best.predict(val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Práctico 4 - Flo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2508604ac6534766b142d8a9d86c12d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3555dfc1ef634a54b67274a1dbbd92f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Processing: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f3ad3c2cac724e099170823b2dc49978",
      "max": 69,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2508604ac6534766b142d8a9d86c12d2",
      "value": 69
     }
    },
    "47482f9ee49d4fcba87f4c0b2397a119": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4e5bf7196dd84ad6ac9b3983e1077c0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "TextModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "TextModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "TextView",
      "continuous_update": true,
      "description": "",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_c19cf648a61745f58eb9b81291f7b17f",
      "placeholder": "​",
      "style": "IPY_MODEL_bd7ee1d668b149f8850b1476ab82a529",
      "value": "Following data types have been inferred automatically, if they are correct press enter to continue or type 'quit' otherwise."
     }
    },
    "a0adfdf2dafb429797aed840ce0131c1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bd7ee1d668b149f8850b1476ab82a529": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c19cf648a61745f58eb9b81291f7b17f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "cbe5a5d40f164b078a980567b7a8e70e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Processing: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0adfdf2dafb429797aed840ce0131c1",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_47482f9ee49d4fcba87f4c0b2397a119",
      "value": 3
     }
    },
    "f3ad3c2cac724e099170823b2dc49978": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
